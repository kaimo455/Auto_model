{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.model_selection import KFold, GroupKFold, StratifiedKFold\n",
    "from sklearn.model_selection import LeaveOneOut, LeavePOut, LeaveOneGroupOut, LeavePGroupsOut\n",
    "from sklearn.model_selection import ShuffleSplit, GroupShuffleSplit, StratifiedShuffleSplit\n",
    "\n",
    "class Preprocessor:\n",
    "    \"\"\"\n",
    "    Data preprocessor:\n",
    "    \n",
    "    - Loading data & parse dates -> data\n",
    "    - Drop specific columns/features -> data\n",
    "    - Drop columns/features by null ratio -> data_dropped \n",
    "    - Drop rows/samples by null ratio -> data_dropped \n",
    "    - Filling null values -> data_fillna\n",
    "    - Encoding features -> data_feat_enc\n",
    "    - PCA dimensionality reduction: -> data_pca\n",
    "      what features to PCA and evr thresholdto choose number of components\n",
    "    - Scaling\n",
    "    \"\"\"\n",
    "    def __init__(self, data_path, data_type='csv', parse_dates=None, **kwargs):\n",
    "        print('Preproocessor initializing...')\n",
    "        # load data\n",
    "        self.data = self.load_data(data_path, data_type, parse_dates, **kwargs)\n",
    "        print('Finished.')\n",
    "    \n",
    "    def load_data(self, data_path, data_type, parse_dates, **kwargs):\n",
    "        \"\"\"\n",
    "        function to load different type of data. Supporting \"csv\".\n",
    "        - parse datetime\n",
    "        - convert columns to corresponding dtype\n",
    "        \"\"\"\n",
    "        print('Loading data from \\'{}\\'...'.format(data_path), end=' ')\n",
    "        # load csv data\n",
    "        if data_type == 'csv':\n",
    "            data = pd.read_csv(data_path, **kwargs)\n",
    "        if data_type == 'xlsx' or data_type == 'xls':\n",
    "            data = pd.read_excel(data_path, **kwargs)\n",
    "        # parse datetime\n",
    "        if parse_dates:\n",
    "            self.date_cols_ = parse_dates\n",
    "            print('Parsing datetime...', end=' ')\n",
    "            for col in parse_dates:\n",
    "                data[col] = pd.to_datetime(data[col], infer_datetime_format=True)\n",
    "        print('Finished.')\n",
    "        return data\n",
    "\n",
    "    def _get_null_stats(self, axis):\n",
    "        \"\"\"\n",
    "        Calculate null values statistic\n",
    "        \"\"\"\n",
    "        # regard np.inf and empty string as null value\n",
    "        pd.options.mode.use_inf_as_na = True\n",
    "        data = self.data.replace('', np.nan)\n",
    "        # check the missing value statistic\n",
    "        null_stats = data.isna().sum(axis=axis) / data.shape[axis]\n",
    "        return null_stats\n",
    "    \n",
    "    def drop_cols(self, cols_to_drop, is_return=False):\n",
    "        \"\"\"\n",
    "        Drop some specific columns\n",
    "        \"\"\"\n",
    "        self.cols_to_drop_ = cols_to_drop\n",
    "        print('Dropping specific column(s)...', end=\" \")\n",
    "        self.data = self.data.drop(cols_to_drop, axis=1)\n",
    "        print('Finished.')\n",
    "        if is_return:\n",
    "            return self.data\n",
    "\n",
    "    def drop_null(self, col_drop_rate, row_drop_rate, is_return=False):\n",
    "        \"\"\"\n",
    "        There we consider `np.NaN`, `np.inf`, ``''``(empty string), `None`  as null values.\n",
    "        \n",
    "        Return `dropped_data` dataframe.\n",
    "        \"\"\"\n",
    "        print(f'Dropping column(s) and row(s) with ratio {col_drop_rate:.2f} and {row_drop_rate:.2f} respectively...', end=' ')\n",
    "        self.col_drop_rate_ = col_drop_rate\n",
    "        self.row_drop_rate_ = row_drop_rate\n",
    "        # deep copy data to dropped_data\n",
    "        dropped_data = self.data.copy(deep=True)\n",
    "        # drop columns\n",
    "        col_null_stats = self._get_null_stats(axis=0)\n",
    "        col_idx = col_null_stats >= col_drop_rate\n",
    "        dropped_data.drop(col_null_stats.index[col_idx], axis=1, inplace=True)\n",
    "        self.data = dropped_data\n",
    "        # drop rows\n",
    "        row_null_stats = self._get_null_stats(axis=1)\n",
    "        row_idx = row_null_stats >= row_drop_rate\n",
    "        dropped_data.drop(row_null_stats.index[row_idx], axis=0, inplace=True)\n",
    "        self.data = dropped_data\n",
    "        print('Finished.')\n",
    "        if is_return:\n",
    "            return self.data\n",
    "\n",
    "    def fill_na(self, fill_na_method, is_return=False):\n",
    "        \"\"\"\n",
    "        Fill NaN cells.\n",
    "        \n",
    "        Return `fillna_data` dataframe\n",
    "        \"\"\"\n",
    "        print('Fill null values...', end=' ')\n",
    "        # deep copy data to fillna_data\n",
    "        fillna_data = self.data.copy(deep=True)\n",
    "        fillna_data.fillna(method=fill_na_method, inplace=True)\n",
    "        self.data = fillna_data\n",
    "        print('Finished.')\n",
    "        if is_return:\n",
    "            return self.data\n",
    "    \n",
    "    def feature_encoding(self, features_to_enc, is_return=False):\n",
    "        \"\"\"\n",
    "        Encoding object/string variables, here we need to avoid NaN values so just using fillna_data\n",
    "        \"\"\"\n",
    "        print('Feature encoding...', end=' ')\n",
    "        # encode each feature\n",
    "        self.les_ = []\n",
    "        for feat in features_to_enc:\n",
    "            # ignore NaN\n",
    "            _df = self.data[feat].copy(deep=True)\n",
    "            le = LabelEncoder()\n",
    "            _df.loc[~_df.isna()] = le.fit_transform(_df.loc[~_df.isna()])\n",
    "            self.data[feat] = _df.astype('category')\n",
    "            # save encoder\n",
    "            self.les_.append(le)\n",
    "        print('Finished.')\n",
    "        if is_return:\n",
    "            return self.data\n",
    "        \n",
    "    def convert_dtypes(self, int_cols=None, float_cols=None, cate_cols=None, bool_cols=None, is_return=False):\n",
    "        # parse dtype\n",
    "        if int_cols:\n",
    "            self.int_cols_ = int_cols\n",
    "            self.data[int_cols] = self.data[int_cols].astype(np.int)\n",
    "        if float_cols:\n",
    "            self.float_cols_ = float_cols\n",
    "            self.data[float_cols] = self.data[float_cols].astype(np.float)\n",
    "        if cate_cols:\n",
    "            self.cate_cols_ = cate_cols\n",
    "            self.data[cate_cols] = self.data[cate_cols].astype('category')\n",
    "        if bool_cols:\n",
    "            self.bool_cols_ = bool_cols\n",
    "            self.data[bool_cols] = self.data[bool_cols].astype('bool')\n",
    "        if is_return:\n",
    "            return self.data\n",
    "    \n",
    "    def dim_reduction_pca(self, features_to_pca, evr_threshold, is_return=False):\n",
    "        \"\"\"\n",
    "        Perform PCA to all features if `features_to_pca` is None, else only on specific features.\n",
    "        \"\"\"\n",
    "        print('Dimensionality reduction using PCA...', end=\" \")\n",
    "        if evr_threshold <= 0 or evr_threshold >= 1:\n",
    "            raise ValueError('evr_threshold must be in range [0, 1]')\n",
    "        data = self.data[features_to_pca] if features_to_pca else self.data\n",
    "        self.pca_ = PCA(n_components=None).fit(data)\n",
    "        pca_data = self.pca_.transform(data)\n",
    "        evrs_cumsum = np.cumsum(self.pca_.explained_variance_ratio_)\n",
    "        for idx, cumsum in enumerate(evrs_cumsum):\n",
    "            if cumsum >= evr_threshold:\n",
    "                self.data = pca_data[:, :idx]\n",
    "        print('Finished.')\n",
    "        if is_return:\n",
    "            return self.data\n",
    "        \n",
    "    def scaling(self, cate_cols, n_cate_to_scale=3, is_return=False):\n",
    "        # numeric columns\n",
    "        int_cols = list(self.data.dtypes.index[self.data.dtypes == np.int].values)\n",
    "        float_cols = list(self.data.dtypes.index[self.data.dtypes == np.float].values)\n",
    "        num_cols = int_cols + float_cols\n",
    "        # category columns\n",
    "        cat_cols = [col for col in cate_cols if len(self.data[col].cat.categories) > n_cate_to_scale]\n",
    "        self.data[num_cols+cat_cols] = StandardScaler().fit_transform(self.data[num_cols+cat_cols])\n",
    "        if is_return:\n",
    "            return self.data\n",
    "    \n",
    "    @staticmethod\n",
    "    def make_folds(X, y=None, n_splits=5, strategy=None, group=None, shuffle=True, random_state=None):\n",
    "        ### strategy = None / 'stratified' / 'group'\n",
    "\n",
    "        # stratified strategy\n",
    "        if strategy == \"stratified\":\n",
    "            spliter = StratifiedKFold(n_splits=n_splits, shuffle=shuffle, random_state=random_state)\n",
    "            if y is None:\n",
    "                raise Exception('Please provide y parameter.')\n",
    "            else:\n",
    "                idx_generator = spliter.split(X, y=y)\n",
    "        # group strategy\n",
    "        elif strategy == 'group':\n",
    "            spliter = GroupKFold(n_splits=n_splits)\n",
    "            if group is None:\n",
    "                raise Exception('Please provide group parameter.')\n",
    "            else:\n",
    "                idx_generator = spliter.split(X, y=y, groups=group)\n",
    "        # not specific strategy\n",
    "        else:\n",
    "            spliter = KFold(n_splits=n_splits, shuffle=shuffle, random_state=random_state)\n",
    "            idx_generator = spliter.split(X, y=y)\n",
    "        return idx_generator\n",
    "    \n",
    "    @staticmethod\n",
    "    def make_leave_out(X, y=None, p=5, strategy=None, group=None):\n",
    "        ### strategy = None / 'group'\n",
    "\n",
    "        # group strategy\n",
    "        if strategy == 'group':\n",
    "            spliter = LeaveOneGroupOut() if p == 1 else LeavePGroupsOut(p)\n",
    "            if group is None:\n",
    "                raise Exception('Please provide group parameter.')\n",
    "            else:\n",
    "                idx_generator = spliter.split(X, y=y, groups=group)\n",
    "        # not specific strategy\n",
    "        else:\n",
    "            spliter = LeaveOneOut() if p == 1 else LeavePOut(p)\n",
    "            idx_generator = spliter.split(X, y=y, groups=group)\n",
    "        return idx_generator\n",
    "    \n",
    "    @staticmethod\n",
    "    def make_shuffle(X, y=None, n_splits=5, test_size=0.25, train_size=0.75, strategy=None, group=None, random_state=None):\n",
    "        ### strategy = None / 'stratified' / 'group'\n",
    "\n",
    "        # stratified strategy\n",
    "        if strategy == \"stratified\":\n",
    "            spliter = StratifiedShuffleSplit(n_splits=n_splits, test_size=test_size, train_size=train_size, random_state=random_state)\n",
    "            if y is None:\n",
    "                raise Exception('Please provide y parameter.')\n",
    "            else:\n",
    "                idx_generator = spliter.split(X, y=y)\n",
    "        # group strategy\n",
    "        elif strategy == 'group':\n",
    "            spliter = GroupShuffleSplit(n_splits=n_splits, test_size=test_size, train_size=train_size, random_state=random_state)\n",
    "            if group is None:\n",
    "                raise Exception('Please provide group parameter.')\n",
    "            else:\n",
    "                idx_generator = spliter.split(X, y=y, groups=group)\n",
    "        # not specific strategy\n",
    "        else:\n",
    "            spliter = ShuffleSplit(n_splits=n_splits, test_size=test_size, train_size=train_size, random_state=random_state)\n",
    "            idx_generator = spliter.split(X, y=y)\n",
    "        return idx_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "## datetime features\n",
    "datetime_cols = ['PROC_DATE', 'CREATE_DT_TM', 'SCHED_START_DT_TM']\n",
    "## integer features\n",
    "int_cols = ['CAV_REC_AGE']\n",
    "## category features\n",
    "cate_cols = ['SCHED_SURG_AREA', 'RACE', 'ETHNIC_GROUP', 'SCHED_HOSPITAL', 'SCHED_SURG_PROC_CD', 'FEMALE', 'CAV_REC_SEX', 'CAV_REC_LANG', 'CAV_REC_IPOP', 'CAV_REC_PRIORITY_CODE', 'CAV_REC_DISP_CODE']\n",
    "## boolean features\n",
    "bool_cols = ['PCPVISIT', 'METFORMIN_FLAG', 'OPIOIDS_FLAG', 'ALPHA_BLOCKERS', 'CENTRAL_ANTAGONISTS', 'RENIN', 'BETA_BLOCKERS', 'ACE_INHIB', 'ARB', 'ALDOSTERONE_BLOCKERS', 'VASODIALATORS', 'DIURETICS', 'CALCIUM_BLOCKERS', 'STATINS', 'INSULIN_MEDS', 'ASPIRIN', 'WARFARIN', 'DOACS', 'PRETERM_17P', 'MEDROL', 'PREDNISONE', 'INHALED_STEROID_WITH_LABA', 'INHALED_STEROID_WITHOUT_LABA', 'INHALED_STEROIDS', 'ASTHMA_BIOLOGICS', 'SHORT_ACTING_BRONCHO_DIALATORS', 'TNF_INHIBITORS', 'IMMUNOMODULATORS', 'AMINOSALICYLATES', 'CORTICOSTEROIDS', 'ARNI', 'ALLOPURINOL', 'SEIZURE', 'MUSCLERELAXANT', 'DIGOXIN', 'INOTROPES', 'ANTI_ARRHYTHMIC', 'ANTIPLATELET', 'SULFONYLUREA', 'GLP_1_AGONIST', 'THIAZOLIDINEDIONE', 'SGLT2_INHIBITOR', 'DPP4_INHIBITOR', 'ALPHA_GLUCOSIDASE_INHIBITOR', 'AMYLINOMIMETIC', 'RAPID_ACTING_INSULIN', 'SHORT_ACTING_INSULIN', 'INTERMEDIATE_ACTING_INSULIN', 'LONG_ACTING_INSULIN', 'MINOCYCLINE', 'DOXYCYCLINE', 'MELATONIN', 'METHAZOLAMIDE', 'HYDROXYCHLOROQUINE', 'ITTC', 'DMARDS', 'OBESE_HST', 'MORBIDOBESE_HST', 'PH_HST', 'AFIB_HST', 'COPD_HST', 'CHF_HST', 'DIAB_HST', 'CAD_HST', 'OSTEO_HST', 'HTN_HST', 'CANCER_HST', 'LUNG_CANCER_HST', 'OVARIAN_CANCER_HST', 'HEAD_NECK_CANCER_HST', 'BREAST_CANCER_HST', 'ASTHMA_HST', 'GERD_HST', 'FIBROMYALGIA_HST', 'DEPRESSION_HST', 'PSORIATIC_ARTHRITIS_HST', 'RHEUM_ARTHRITIS_HST', 'LUPUS_HST', 'VTVF_HST', 'STROKE_HST', 'VASCULARDISEASE_HST', 'LOWBACKPAIN_HST', 'DVT_HST', 'PE_HST', 'HYPOTHYROIDISM_HST', 'ADRENAL_INSUFFICIENCY_HST', 'INFERTILITY_HST', 'CKD_HST', 'ESRD_HST', 'OBS_SLEEPAPNEA_HST' , 'CARDIAC_ARREST_HST', 'HEMO_STROKE_HST', 'MAJOR_BLEED_HST', 'MACULAR_DEGEN_HST', 'ANXIETY_HST', 'HYPERLIPIDEMIA_HST', 'HIV_HST', 'ALZHEIMER_HST', 'COLORECTAL_CANCER_HST', 'ENDOMETRIAL_CANCER_HST', 'GLAUCOMA_HST', 'HIP_PELVIC_FRACTURE_HST', 'BENIGN_PROSTATIC_HYPERPLASIA_HST', 'CIRRHOSIS_HST', 'CIRRHOSIS_HST_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preproocessor initializing...\n",
      "Loading data from './data/PYTHON_LAB_DF_TEST_2.csv'... Parsing datetime... Finished.\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "preprocessor = Preprocessor(data_path='./data/PYTHON_LAB_DF_TEST_2.csv', \\\n",
    "                            data_type='csv', \\\n",
    "                            parse_dates=datetime_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping column(s) and row(s) with ratio 0.50 and 0.10 respectively... Finished.\n",
      "Fill null values... Finished.\n",
      "Fill null values... Finished.\n",
      "Feature encoding... Finished.\n",
      "Dropping specific column(s)... Finished.\n"
     ]
    }
   ],
   "source": [
    "preprocessor.drop_null(0.5, 0.1)\n",
    "preprocessor.fill_na('ffill')\n",
    "preprocessor.fill_na('bfill')\n",
    "preprocessor.feature_encoding(cate_cols)\n",
    "preprocessor.scaling(cate_cols)\n",
    "preprocessor.convert_dtypes(int_cols=int_cols, cate_cols=cate_cols, bool_cols=bool_cols)\n",
    "preprocessor.drop_cols(['FEMALE'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
